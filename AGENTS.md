# AGENTS 工作记录

## 2026-02-08

- 阅读并遵循 `.ai/claude.prompt.md` 与 `.ai/context/01-overview.md`。
- 新增 Anima 训练桥接入口：`anima_train_network.py`（将参数转发到根仓 `anima_train.py`）。
- 新增 Anima 适配器网络模块：
  - `networks/lora_anima.py`
  - `networks/lokr_anima.py`
  - `networks/_anima_adapter_common.py`（内置 LoRA/LoKr 注入实现，无外部 LyCORIS 依赖）。
- 新增 Anima 模型/策略模块：
  - `library/anima_models.py`
  - `library/strategy_anima.py`
- 新增文档：`docs/anima_train_network.md`，并在 `README.md`、`README-ja.md` 增加入口链接。
- 新增测试：
  - `tests/test_anima_network_modules.py`
  - `tests/test_anima_train_network.py`
- 执行测试：`4 passed`（针对新增 Anima 模块与桥接脚本）。
- 新增并启用本地后端/运行时模块，推进 `sd-scripts-anima` 独立化：
  - `library/anima_backend/modelling/*`（vendor Anima transformer / cosmos_predict2 / wan vae）
  - `library/anima_runtime/model_loading.py`
  - `library/anima_runtime/flow_training.py`
  - `library/anima_runtime/config_adapter.py`
- 将 `anima_train_network.py` 从桥接入口改为原生 `NetworkTrainer` 实现：
  - 移除桥接参数（`--anima-train-py` / `--print-cmd` / `--dry-run`）
  - 增加本地加载与参数校验（含 `RAdamScheduleFree` 约束）
  - 训练语义对齐为 `Qwen -> preprocess_text_embeds(qwen_hidden, t5_ids) -> Anima Transformer`
- 强制 T5 链路：`t5_tokenizer_dir` 必填，训练 batch 中 `t5_ids` 缺失直接报错。
- 切断外部依赖路径：
  - `library/anima_models.py` 仅调用本地 `library/anima_runtime/*`
  - 移除父目录探测、`sys.path` 注入与 `models.*` 虚拟包依赖
- 更新文档：
  - 重写 `docs/anima_train_network.md` 为独立原生训练说明
  - 更新 `README.md` / `README-ja.md` 标注 Anima 入口不依赖上级仓库
- 更新/新增测试：
  - 更新 `tests/test_anima_train_network.py`
  - 新增 `tests/test_anima_independence.py`
  - 新增 `tests/test_anima_process_batch.py`

## 2026-02-09

- 读取并遵循 `AGENTS.md`、`.ai/claude.prompt.md`、`.ai/context/01-overview.md`。
- 按 `README.md` 的 Windows 安装流程配置项目虚拟环境（`e:\sd-scripts-anima\venv`）：
  - 使用 `Python 3.10` 创建 venv（避免默认 `Python 3.14` 兼容性风险）。
  - 在 venv 内升级 `pip`、`setuptools`、`wheel`。
  - 安装 `torch==2.6.0`、`torchvision==0.21.0`（CUDA 12.4）。
  - 安装并升级 `requirements.txt` 全量依赖。
- 验证环境：
  - `python` 版本：`3.10.6`
  - `torch` 版本：`2.6.0+cu124`
  - `torch.cuda.is_available()`：`True`
  - 初始失败：`anima_train_network.py` 直接访问缺失字段 `cache_text_encoder_outputs`。
  - 后续失败：`Anima` 缺少 `enable_gradient_checkpointing`、`device` 接口兼容问题。
  - 后续失败：`AnimaAdapterNetwork` 缺少 `prepare_grad_etc` 接口。
  - 10 step 冒烟阶段失败：默认配置在首步前 OOM，且分辨率/裁剪桶配置与数据集尺寸存在冲突（`image too large` 断言）。
- 形成审查结论：当前 Anima 原生入口与通用 `train_network.py` 之间存在多处接口契约未对齐，另有 `config_adapter` 映射语义问题（如 `max_steps` 与 `epochs`、`lr_scheduler_num_cycles` 精度丢失、bucket相关参数映射不完整）。
- 按“切换到 Kohya 原生配置”方案实施修复：
  - `anima_train_network.py`：
    - 移除 root-style `--config` 入口与运行时映射调用。
    - 保留并继续使用优化器别名规范化。
    - 禁用 argparse 缩写（`allow_abbrev=False`），防止 `--config` 被误解析为 `--config_file`。
    - 保持并增强参数健壮性（可选字段通过 `getattr` 读取，`gradient_checkpointing` 对 Anima 强制降级关闭）。
  - `library/anima_runtime/config_adapter.py`：
    - 删除 root-style 运行时配置映射逻辑，仅保留优化器别名工具（`coerce_optimizer_type` / `normalize_optimizer_aliases`）。
  - `library/train_util.py`：
    - 将 `--lr_scheduler_num_cycles` 参数类型由 `int` 调整为 `int_or_float`，支持如 `0.5`。
  - 新增迁移工具：
    - `tools/convert_anima_root_to_kohya.py`（旧 root-style TOML -> `train_args.toml` + `dataset.toml`）。
  - 文档更新：
    - 重写 `docs/anima_train_network.md`，明确只支持 Kohya 原生配置，`--config` 已移除，并加入迁移工具与 10-step smoke 模板说明。
    - 更新 `README.md`、`README-ja.md` 的 Anima 条目，补充新配置策略与迁移脚本入口。
  - 新增 smoke 配置模板：
    - `configs/smoke/anima_10steps_train_args.toml`
    - `configs/smoke/anima_dataset.toml`
  - 测试更新/新增：
    - 更新 `tests/test_anima_train_network.py`（移除 root-style 适配测试，新增 `--config` 移除与健壮性断言）。
    - 更新 `tests/test_anima_network_modules.py`（覆盖 `prepare_grad_etc` 等训练契约方法）。
    - 更新 `tests/anima_entry_test_utils.py`（`lr_scheduler_num_cycles` 浮点兼容）。
    - 新增 `tests/test_scheduler_num_cycles_float.py`。
    - 新增 `tests/test_anima_config_converter.py`。
- 验证说明：
  - 受环境网络策略限制，无法安装 `pytest`（访问包索引被拒绝），未能执行完整 pytest 套件。
  - 已执行替代自检：
    - `python -m compileall` 对核心变更文件进行语法校验通过。
    - 运行内联 Python 断言，验证：`--config` 不再可用、`lr_scheduler_num_cycles` 支持浮点、迁移脚本关键映射正确、Anima 网络契约方法可调用。
  - 模型路径根目录：`E:\sd-scripts-anima\anima-models`
  - 命令：`accelerate launch anima_train_network.py ... --max_train_steps 10`（`batch_size=1`, `resolution=512`, `enable_bucket=true`, `anima_seq_len=128`）
  - 结果：训练成功完成 10 steps，退出码 `0`，并输出 checkpoint：
- 对 smoke 产出的 LoKr 权重做结构/数值体检：
  - 文件可正常读取：`1020` tensors，metadata 完整（`ss_network_module=networks.lokr_anima`，`ss_network_dim=8`，`ss_max_train_steps=10`）。
  - 无数值异常：`NaN/Inf` 均为 `0`。
  - 但发现可疑点：所有 `lokr_w2_b` 张量全为 `0`（`340/340`），而 `lokr_w1`、`lokr_w2_a` 非零；这意味着 LoKr 分解中的输出分支可能未产生有效更新。
  - `step00000010` 与最终 `last` 文件的 tensor 值完全一致（仅 metadata 差异导致 hash 不同）。
- 按“固定 LLMAdapter 模式、T5 强依赖”计划完成修复：
  - `networks/_anima_adapter_common.py`
    - `prepare_grad_etc` 改为恢复 adapter 参数 `requires_grad=True`，并显式将注入层设为 `train()`。
    - `on_epoch_start` 同步恢复参数可训练状态，避免 `unet.requires_grad_(False)` 后 adapter 长期冻结。
  - `anima_train_network.py`
    - 移除训练路径中 `preprocess_text_embeds(...)` 的 `torch.no_grad()` 包裹（Qwen 仍保持 `no_grad=True`）。
    - 维持 T5 强依赖校验（`t5_tokenizer_dir` 必填、batch 中 `t5_ids` 缺失直接报错）。
  - `library/strategy_anima.py`
    - 增加 `t5_input_ids` 非空校验，禁止无 T5 回退路径。
  - `library/anima_backend/modelling/anima_modeling.py`
    - 增加 `enable_gradient_checkpointing` no-op 兼容接口，避免外部误调用崩溃。
  - `tools/convert_anima_root_to_kohya.py`
    - 增加 `model.t5_tokenizer_dir / model.t5_tokenizer_path` 强校验；缺失时报清晰错误。
  - 文档与模板更新：
    - `docs/anima_train_network.md`、`README.md`、`README-ja.md` 明确 LLMAdapter 训练语义默认启用且 T5 必需。
    - `configs/smoke/anima_10steps_train_args.toml` 增加 T5 必填说明注释。
- 测试更新与验证：
  - 更新 `tests/test_anima_network_modules.py`：新增 `unet.requires_grad_(False)` 后 `prepare_grad_etc` 恢复断言。
  - 更新 `tests/test_anima_process_batch.py`：新增
    - 缺失 `t5_ids` 报错断言；
    - `preprocess_text_embeds` 梯度可回传断言。
  - 更新 `tests/test_anima_config_converter.py`：新增缺失 T5 配置转换失败断言。
  - 在 venv 安装 `pytest` 后执行：
    - `pytest -q tests/test_anima_network_modules.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_scheduler_num_cycles_float.py tests/test_anima_config_converter.py`
    - 结果：`16 passed`。
  - 训练输出：
  - 结果：训练 10 steps 成功完成，退出码 `0`。
  - 权重体检：`lokr_w2_b` 不再全零（`0/340` 为零，`340/340` 非零），与修复目标一致。
- 新增“训练启动时自动下载 T5 文件”能力：
  - `library/anima_runtime/model_loading.py`
    - 新增 `T5_DEFAULT_REPO_ID=google/t5-v1_1-base`。
    - 新增缺失文件检测与自动下载流程：当 `t5_tokenizer_dir` 缺 `config.json` / `spiece.model` / `tokenizer.json` 时，默认自动下载并落盘。
    - `load_t5_tokenizer(...)` 扩展参数：
      - `auto_download`（默认 `True`）
      - `repo_id`（默认 `google/t5-v1_1-base`）
    - 下载后强制本地加载（`local_files_only=True`）。
  - `library/anima_models.py`
    - `load_anima_t5_tokenizer` 支持透传自动下载参数。
  - `anima_train_network.py`
    - 新增 CLI 参数：
      - `--auto_download_t5_tokenizer/--no-auto_download_t5_tokenizer`
      - `--t5_tokenizer_repo_id`
    - `get_tokenize_strategy` 调用 T5 加载时传入上述参数。
- 文档更新：
  - `docs/anima_train_network.md`：增加自动下载参数与行为说明。
  - `README.md` / `README-ja.md`：增加“默认自动下载 T5 文件”说明。
- 新增测试：
  - `tests/test_anima_t5_auto_download.py`
    - 覆盖“缺文件自动下载”路径。
    - 覆盖“关闭自动下载时缺文件直接报错”路径。
- 测试执行：
  - `pytest -q tests/test_anima_t5_auto_download.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_network_modules.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`18 passed`。
- 真实下载验证：
  - 通过 `load_t5_tokenizer('output/t5_autodl_smoke_<uuid>', auto_download=True)` 在启动阶段成功自动下载并生成所需文件：
    - `config.json`
    - `spiece.model`
    - `tokenizer.json`
- 按“Comfy-only 导出 + train_norm 默认开启”实施细化修复：
  - `anima_train_network.py`
    - 新增 `--train_norm/--no-train_norm`（默认 `True`）。
    - 新增 `apply_anima_network_defaults(args)`，在启动阶段将 `train_norm=<true|false>` 强制注入 `network_args`，确保网络模块可读取。
  - `networks/_anima_adapter_common.py`
    - 新增统一布尔解析 `_parse_bool`，修复字符串布尔值误判风险。
    - `apply_to` 增加 Norm 参数收集（`LayerNorm` / `RMSNorm` / 自定义 `RMSNorm` 类名识别），并把 Norm 参数加入训练参数集合。
    - 记录 Norm 初始参数快照，导出时以差分写入 `w_norm/b_norm`。
    - 导出改为 Comfy-only 键：统一写入 `diffusion_model.*`。
    - LoRA/LoKr 导出新增 `.alpha` 键，避免缩放语义丢失。
    - 加载逻辑支持 Comfy 键回读（含 `diffusion_model.*` 与旧格式兼容），并支持 Norm 差分回填。
- 新增/更新测试：
  - 更新 `tests/test_anima_network_modules.py`
    - 增加 `train_norm=true/false` 行为断言；默认开启时 Norm 参数进入优化器参数集。
    - Dummy 模型增加 `llm_adapter` 与 norm 结构覆盖。
  - 更新 `tests/test_anima_train_network.py`
    - 增加 `--train_norm` 默认值、`--no-train_norm` 解析、`network_args` 注入断言。
  - 新增 `tests/test_anima_comfy_export_keys.py`
    - 断言导出键全部以 `diffusion_model.` 开头。
    - 断言 LoRA/LoKr 后缀、`.alpha`、`w_norm/b_norm`、`llm_adapter` 键存在。
- 文档同步：
  - `docs/anima_train_network.md`：补充 `train_norm` 默认开启、Comfy-only 导出、`--resume` 续训建议。
  - `README.md` / `README-ja.md`：补充上述行为摘要。
- 回归验证：
  - `pytest -q tests/test_anima_independence.py tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py tests/test_anima_config_converter.py`
  - 结果：`24 passed`。
  - 结果：10 steps 成功完成，输出：
  - 权重体检：
    - 全部键满足 `diffusion_model.*`。
    - 包含 `llm_adapter`、`w_norm`、`.alpha`、`lokr_w2_b`。
    - `lokr_w2_b` 非零比例 `1.0`（`768000/768000`）。
    - metadata 中 `ss_network_args` 含 `{"train_norm": "true", ...}`。
- 按“LoKr Full-Matrix Sentinel + Cosmos T5 回退”计划完成实现：
  - `networks/_anima_adapter_common.py`
    - 引入 `network_dim >= 100000` 的 Kohya/LyCORIS sentinel 语义：自动强制 `lokr_full_matrix=true`（不改写 dim）。
    - 增加触发日志，便于训练日志可观测性。
  - `library/anima_runtime/model_loading.py`
    - 新增 T5 源解析：支持 HF repo id、HF URL、ModelScope URL。
    - 新增 `repo_subfolder`、ModelScope fallback 配置参数。
    - 自动下载改为 HF 优先；HF 失败（含 gated/网络异常）后自动回退 ModelScope。
  - `anima_train_network.py`
    - 新增并透传参数：
      - `--t5_tokenizer_subfolder`
      - `--t5_tokenizer_modelscope_fallback/--no-t5_tokenizer_modelscope_fallback`
      - `--t5_tokenizer_modelscope_repo_id`
      - `--t5_tokenizer_modelscope_revision`
      - `--t5_tokenizer_modelscope_subfolder`
    - `network_dim = 100000`（full-matrix sentinel）
    - T5 下载源改为 `https://huggingface.co/nvidia/Cosmos-Predict2-2B-Text2Image/tree/main/tokenizer`
    - 开启并配置 ModelScope 自动回退。
- 新增/更新测试：
  - `tests/test_anima_network_modules.py`
    - 新增 `network_dim=100000` 自动 full-matrix 断言。
  - `tests/test_anima_t5_auto_download.py`
    - 新增 HF 成功不回退、HF 失败回退 ModelScope、HF/HF URL/ModelScope URL 解析断言。
  - `tests/test_anima_train_network.py`
    - 新增 ModelScope fallback CLI 默认值与关闭开关解析断言。
- 测试验证：
  - `pytest -q tests/test_anima_network_modules.py tests/test_anima_train_network.py tests/test_anima_t5_auto_download.py tests/test_anima_process_batch.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`30 passed`。
  - `pytest -q tests/test_anima_independence.py tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`34 passed`。
- 实测验证：
  - T5 回退下载验证：使用 HF Cosmos URL 作为源，触发 HF gated 后自动回退 ModelScope 成功，下载并校验文件：
    - `config.json`
    - `spiece.model`
    - `tokenizer.json`
    - `tokenizer_config.json`
    - `special_tokens_map.json`
    - 输出：
    - 日志确认 sentinel 触发：`network_dim=100000 >= 100000, forcing lokr_full_matrix=true`
    - 权重体检：存在 `.lokr_w2`、不存在 `.lokr_w2_b`（符合 full-matrix 预期），键前缀全部为 `diffusion_model.*`。
- 按“sd-scripts-anima × Anima_Trainer 稳定性优先”计划补齐三项能力：
  - 续训一致性快照：
    - `train_network.py` 新增通用 hook：`build_resume_snapshot` / `validate_resume_snapshot`，并在 save/load state hook 中读写 `resume_snapshot.json`。
    - `anima_train_network.py` 实现 Anima 侧关键字段快照与严格差异校验（不一致时启动阶段直接报错）。
  - 训练监控增强：
    - `anima_train_network.py` 新增 `--anima_monitor_*` 参数（显存监控、告警策略、阈值配置）。
    - step logs 增加 `gpu/mem_*` 与 `alert/*` 指标；`alert_policy=raise` 时对 `nonfinite_loss` / `memory_near_limit` 触发中断。
  - T5 严格校验：
    - `library/anima_runtime/model_loading.py` 新增 `strict_validation` 路径；
    - `--t5_tokenizer_validate_strict` 接入 `anima_train_network.py`；
    - 严格模式校验 special token、id 范围与本地 smoke encode。
- 测试补充：
  - 新增 `tests/test_anima_resume_snapshot.py`。
  - 新增 `tests/test_anima_monitoring.py`。
  - 更新 `tests/test_anima_train_network.py`（新 CLI 参数默认值与解析）。
  - 更新 `tests/test_anima_t5_auto_download.py`（strict 模式成功/失败路径）。
  - 更新 `tests/anima_entry_test_utils.py`（stub `NetworkTrainer` 增加 log/snapshot 接口）。
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_t5_auto_download.py tests/test_anima_resume_snapshot.py tests/test_anima_monitoring.py tests/test_anima_network_modules.py tests/test_anima_process_batch.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`43 passed`。

## 2026-02-11

- 读取并遵循 `AGENTS.md`、`.ai/claude.prompt.md`、`.ai/context/01-overview.md`。
- 对比分析 ComfyUI 两个 Anima LoKr 权重：
  - `E:\AI\ComfyUI\models\loras\anima\zxiong\e50\newzx-anima-lokr.safetensors`
  - `E:\AI\ComfyUI\models\loras\anima\3in1\DragonOCs-anima-lokr.safetensors`
- 关键结论：
  - 两者均为 Comfy 前缀键（`diffusion_model.*`），目标模块覆盖总体一致。
  - `newzx` 为 `networks.lokr_anima` 导出，启用 `train_norm=true`，且为 full-matrix 形态（存在 `.lokr_w2`，无 `.lokr_w2_b`）。
  - `DragonOCs` 为 `lycoris.kohya` 导出（`algo=lokr, full_matrix=true`）。
  - `newzx` metadata 显示实际训练总步数 `ss_steps=300`（`ss_epoch=50`，`batch=6`，`grad_accum=6`）。
  - 权重强度对比：`newzx` 的 `lokr_w2` 平均绝对值约 `0.00063`，`DragonOCs` 约 `0.00161`，前者约为后者 `39%`，整体更弱；`newzx` 另含 norm 差分键（`w_norm/b_norm`）。
- 结论用于答复用户“为什么一个能吐原图、一个不能”：更可能是训练步数/有效更新不足与权重强度偏弱叠加所致，而非基础键格式不兼容。
- 复核 `anima_train_network.py` 当前网络加载约束：`SUPPORTED_NETWORK_MODULES=("networks.lora_anima", "networks.lokr_anima")`，默认回落为 `networks.lora_anima`，不接受 `lycoris.kohya` 作为训练入口模块。
- 结论：当前 `sd-scripts-anima` 训练脚本使用本仓 Anima 适配实现（内置 LoRA/LoKr 注入），并非直接依赖 LyCORIS 训练实现；但导出权重仍兼容常见 LoKr 语义（含 full-matrix sentinel 行为）。
- 按“参考 LyCORIS 实现但保持键名与训练层不变”完成网络实现细化：
  - 修改 `networks/_anima_adapter_common.py`：
    - 为 `_LoRALayer` / `_LoKrLayer` 增加 `set_alpha(...)`，支持从权重 `.alpha` 回读并即时更新缩放。
    - `_LoKrLayer` 的 rank dropout 改为按 rank 维度掩码并进行 `1/(1-p)` 期望缩放补偿，语义更贴近 LyCORIS。
    - 保持导出键名不变：仍为 `diffusion_model.*`，并继续导出 `.alpha`。
    - 保持训练层筛选不变：仍由既有 `target_modules` 匹配逻辑决定。
    - `_load_adapter_state_dict` 新增 `.alpha` 读取并应用到对应 layer adapter（仅行为对齐，不改变键结构）。
- 新增测试（`tests/test_anima_network_modules.py`）：
  - `test_lora_alpha_is_restored_from_weights`
  - `test_lokr_alpha_is_restored_from_weights`
  - 验证从 safetensors 加载后 `.alpha` 会正确恢复并影响 scaling。
- 验证：
  - `python -m pytest -q tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py` -> `8 passed`
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py` -> `28 passed`
- 按需求实现“默认 TensorBoard + 实验名日志命名 + xformers 完整支持”：
  - `anima_train_network.py`
    - 新增 `apply_anima_runtime_defaults(args)`：
      - 默认启用 `log_with=tensorboard`；
      - 默认日志根目录为 `<output_dir>/logs`（无 `output_dir` 时为 `logs`）；
      - 默认 `log_prefix=<output_name>_`（用于组合“实验名 + 时间戳”目录）；
      - 兼容历史拼写 `xfomers` 并映射到 `xformers`。
    - 在 `__main__` 流程中接入 `apply_anima_runtime_defaults(args)`。
    - 在 `assert_extra_args` 中补齐 xformers backend 选择逻辑：
      - `--xformers` 强制 `anima_attention_backend=xformers`；
      - 若 xformers 不可用，自动回退 `torch` 并输出 warning。
    - 增加 `--xfomers` 兼容参数（若基类未定义时注册，避免冲突）。
  - `library/train_util.py`
    - `prepare_accelerator` 改为仓库级默认启用 TensorBoard（未指定 `log_with` 时）。
    - 默认日志根目录：未传 `logging_dir` 时自动使用 `<output_dir>/logs`（无 `output_dir` 时 `logs`）。
    - 日志目录命名改为“实验名 + 详细日期”：`<log_prefix><YYYYMMDD_HHMMSS_ffffff>`。
- 测试更新：
  - `tests/test_anima_train_network.py`
    - 新增运行时日志默认值断言；
    - 新增 `xfomers` 兼容映射断言；
    - 新增 xformers 可用/不可用时 backend 选择与回退断言（monkeypatch `_is_xformers_available`）。
  - `tests/anima_entry_test_utils.py`
    - 补充 stub parser 字段：`logging_dir/log_with/log_prefix/mem_eff_attn/sdpa/xfomers`。
- 文档同步：
  - `docs/anima_train_network.md`：新增默认 TensorBoard、日志命名规则、xformers 行为与 `xfomers` 兼容说明。
  - `README.md` / `README-ja.md`：Anima 条目补充默认日志与 xformers 行为摘要。
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py` -> `31 passed`。
  - `python -m compileall anima_train_network.py library/train_util.py networks/_anima_adapter_common.py` 通过。
- 补全 `configs/kieed.toml` 为可调参数模板：
  - 保留现有 Kieed 训练核心参数并修正输出命名（`output_dir/output_name` 对应 kieed）。
  - 按模块新增/补齐常用可调项与注释：
    - T5 自动下载与 strict 校验
    - LoRA/LoKr（含 `network_args` 示例）
    - 保存/续训策略（state/steps/epochs）
    - 学习率调度扩展参数
    - 运行时与注意力后端（xformers/legacy `xfomers` 说明）
    - 日志与 tracker（TensorBoard 默认行为说明）
    - Anima 监控告警参数
    - 数据增强与 bucket 扩展参数
- 执行 TOML 语法校验：`toml.load('configs/kieed.toml')` 通过（`58` keys）。
- 按用户要求重排 `configs/kieed.toml`：
  - 将常用参数前置（模型路径、T5、数据集、训练核心、网络与输出、性能设置）。
  - 全量注释改为中英双语（中文 + English）。
  - 保持现有训练值不变，仅调整组织结构与注释可读性。
- 语法校验：`toml.load('configs/kieed.toml')` 通过（`58` keys）。
- 修正 `configs/kieed.toml` 关键配置错误：
  - `anima_attention_backend` 从 `"xfomers"` 更正为 `"xformers"`（前者不在允许值内，会触发 argparse choices 校验失败）。
  - 将底部兼容别名 `xfomers = true` 改为注释，避免与 `xformers = true` 重复定义造成混淆。
- 执行 TOML 校验：`toml.load('configs/kieed.toml')` 通过（`60` keys）。
- 排查“TensorBoard 在哪里”：
  - 发现事件文件已生成：
    - `E:\sd-scripts-anima\output\kieed_e20_bs6\logs\kieed-anima-lokr_20260211_152511_753629\network_train\events.out.tfevents.1770794863.DESKTOP-3090.64924.0`
  - 发现 TensorBoard 启动失败原因为：`ModuleNotFoundError: No module named 'pkg_resources'`（当前环境 `setuptools==82.0.0` 不再提供该模块）。
  - 修复：将 venv 中 `setuptools` 降级到 `<81`（安装为 `80.10.2`），随后验证：
    - `python -m tensorboard.main --version` -> `2.20.0` 成功。
- 按“最快启动训练”目标重写 README：`README.md` 改为中英双语 Quick Start，聚焦最小可运行路径（安装 -> 数据 -> 配置 -> 启动 -> TensorBoard）。
- 新增依赖安装向导：`docs/anima_dependency_guide.md`（中英双语，含 Windows/Linux、xformers 可选安装与常见报错处理）。
- 重写 `docs/anima_train_network.md` 为精简版中英双语说明，保留最小必填参数与高频参数，移除不常用参数说明。
- 新增精简示例（参考 `configs/kieed.toml` 并去除低频项）：
  - `configs/examples/anima_quickstart_train_args.toml`
  - `configs/examples/anima_quickstart_dataset.toml`
- 语法校验：使用 `tomllib` 解析上述两个示例 TOML，均通过。
- 对本地剩余改动执行回归验证（xformers/TensorBoard 默认行为与 LoRA/LoKr alpha 加载相关变更）：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_network_modules.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py tests/test_anima_comfy_export_keys.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py tests/test_anima_resume_snapshot.py tests/test_anima_monitoring.py`
  - 结果：`51 passed`。
- 执行语法校验：`python -m compileall anima_train_network.py library/train_util.py networks/_anima_adapter_common.py tests/anima_entry_test_utils.py tests/test_anima_network_modules.py tests/test_anima_train_network.py` 通过。
- 按用户要求提交其余本地改动，`configs/kieed.toml` 继续保持未跟踪且不纳入提交。
