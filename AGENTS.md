# AGENTS 工作记录

## 2026-02-08

- 阅读并遵循 `.ai/claude.prompt.md` 与 `.ai/context/01-overview.md`。
- 新增 Anima 训练桥接入口：`anima_train_network.py`（将参数转发到根仓 `anima_train.py`）。
- 新增 Anima 适配器网络模块：
  - `networks/lora_anima.py`
  - `networks/lokr_anima.py`
  - `networks/_anima_adapter_common.py`（内置 LoRA/LoKr 注入实现，无外部 LyCORIS 依赖）。
- 新增 Anima 模型/策略模块：
  - `library/anima_models.py`
  - `library/strategy_anima.py`
- 新增文档：`docs/anima_train_network.md`，并在 `README.md`、`README-ja.md` 增加入口链接。
- 新增测试：
  - `tests/test_anima_network_modules.py`
  - `tests/test_anima_train_network.py`
- 执行测试：`4 passed`（针对新增 Anima 模块与桥接脚本）。
- 新增并启用本地后端/运行时模块，推进 `sd-scripts-anima` 独立化：
  - `library/anima_backend/modelling/*`（vendor Anima transformer / cosmos_predict2 / wan vae）
  - `library/anima_runtime/model_loading.py`
  - `library/anima_runtime/flow_training.py`
  - `library/anima_runtime/config_adapter.py`
- 将 `anima_train_network.py` 从桥接入口改为原生 `NetworkTrainer` 实现：
  - 移除桥接参数（`--anima-train-py` / `--print-cmd` / `--dry-run`）
  - 增加本地加载与参数校验（含 `RAdamScheduleFree` 约束）
  - 训练语义对齐为 `Qwen -> preprocess_text_embeds(qwen_hidden, t5_ids) -> Anima Transformer`
- 强制 T5 链路：`t5_tokenizer_dir` 必填，训练 batch 中 `t5_ids` 缺失直接报错。
- 切断外部依赖路径：
  - `library/anima_models.py` 仅调用本地 `library/anima_runtime/*`
  - 移除父目录探测、`sys.path` 注入与 `models.*` 虚拟包依赖
- 更新文档：
  - 重写 `docs/anima_train_network.md` 为独立原生训练说明
  - 更新 `README.md` / `README-ja.md` 标注 Anima 入口不依赖上级仓库
- 更新/新增测试：
  - 更新 `tests/test_anima_train_network.py`
  - 新增 `tests/test_anima_independence.py`
  - 新增 `tests/test_anima_process_batch.py`

## 2026-02-09

- 读取并遵循 `AGENTS.md`、`.ai/claude.prompt.md`、`.ai/context/01-overview.md`。
- 按 `README.md` 的 Windows 安装流程配置项目虚拟环境（`e:\sd-scripts-anima\venv`）：
  - 使用 `Python 3.10` 创建 venv（避免默认 `Python 3.14` 兼容性风险）。
  - 在 venv 内升级 `pip`、`setuptools`、`wheel`。
  - 安装 `torch==2.6.0`、`torchvision==0.21.0`（CUDA 12.4）。
  - 安装并升级 `requirements.txt` 全量依赖。
- 验证环境：
  - `python` 版本：`3.10.6`
  - `torch` 版本：`2.6.0+cu124`
  - `torch.cuda.is_available()`：`True`
  - 初始失败：`anima_train_network.py` 直接访问缺失字段 `cache_text_encoder_outputs`。
  - 后续失败：`Anima` 缺少 `enable_gradient_checkpointing`、`device` 接口兼容问题。
  - 后续失败：`AnimaAdapterNetwork` 缺少 `prepare_grad_etc` 接口。
  - 10 step 冒烟阶段失败：默认配置在首步前 OOM，且分辨率/裁剪桶配置与数据集尺寸存在冲突（`image too large` 断言）。
- 形成审查结论：当前 Anima 原生入口与通用 `train_network.py` 之间存在多处接口契约未对齐，另有 `config_adapter` 映射语义问题（如 `max_steps` 与 `epochs`、`lr_scheduler_num_cycles` 精度丢失、bucket相关参数映射不完整）。
- 按“切换到 Kohya 原生配置”方案实施修复：
  - `anima_train_network.py`：
    - 移除 root-style `--config` 入口与运行时映射调用。
    - 保留并继续使用优化器别名规范化。
    - 禁用 argparse 缩写（`allow_abbrev=False`），防止 `--config` 被误解析为 `--config_file`。
    - 保持并增强参数健壮性（可选字段通过 `getattr` 读取，`gradient_checkpointing` 对 Anima 强制降级关闭）。
  - `library/anima_runtime/config_adapter.py`：
    - 删除 root-style 运行时配置映射逻辑，仅保留优化器别名工具（`coerce_optimizer_type` / `normalize_optimizer_aliases`）。
  - `library/train_util.py`：
    - 将 `--lr_scheduler_num_cycles` 参数类型由 `int` 调整为 `int_or_float`，支持如 `0.5`。
  - 新增迁移工具：
    - `tools/convert_anima_root_to_kohya.py`（旧 root-style TOML -> `train_args.toml` + `dataset.toml`）。
  - 文档更新：
    - 重写 `docs/anima_train_network.md`，明确只支持 Kohya 原生配置，`--config` 已移除，并加入迁移工具与 10-step smoke 模板说明。
    - 更新 `README.md`、`README-ja.md` 的 Anima 条目，补充新配置策略与迁移脚本入口。
  - 新增 smoke 配置模板：
    - `configs/smoke/anima_10steps_train_args.toml`
    - `configs/smoke/anima_dataset.toml`
  - 测试更新/新增：
    - 更新 `tests/test_anima_train_network.py`（移除 root-style 适配测试，新增 `--config` 移除与健壮性断言）。
    - 更新 `tests/test_anima_network_modules.py`（覆盖 `prepare_grad_etc` 等训练契约方法）。
    - 更新 `tests/anima_entry_test_utils.py`（`lr_scheduler_num_cycles` 浮点兼容）。
    - 新增 `tests/test_scheduler_num_cycles_float.py`。
    - 新增 `tests/test_anima_config_converter.py`。
- 验证说明：
  - 受环境网络策略限制，无法安装 `pytest`（访问包索引被拒绝），未能执行完整 pytest 套件。
  - 已执行替代自检：
    - `python -m compileall` 对核心变更文件进行语法校验通过。
    - 运行内联 Python 断言，验证：`--config` 不再可用、`lr_scheduler_num_cycles` 支持浮点、迁移脚本关键映射正确、Anima 网络契约方法可调用。
  - 模型路径根目录：`E:\sd-scripts-anima\anima-models`
  - 命令：`accelerate launch anima_train_network.py ... --max_train_steps 10`（`batch_size=1`, `resolution=512`, `enable_bucket=true`, `anima_seq_len=128`）
  - 结果：训练成功完成 10 steps，退出码 `0`，并输出 checkpoint：
- 对 smoke 产出的 LoKr 权重做结构/数值体检：
  - 文件可正常读取：`1020` tensors，metadata 完整（`ss_network_module=networks.lokr_anima`，`ss_network_dim=8`，`ss_max_train_steps=10`）。
  - 无数值异常：`NaN/Inf` 均为 `0`。
  - 但发现可疑点：所有 `lokr_w2_b` 张量全为 `0`（`340/340`），而 `lokr_w1`、`lokr_w2_a` 非零；这意味着 LoKr 分解中的输出分支可能未产生有效更新。
  - `step00000010` 与最终 `last` 文件的 tensor 值完全一致（仅 metadata 差异导致 hash 不同）。
- 按“固定 LLMAdapter 模式、T5 强依赖”计划完成修复：
  - `networks/_anima_adapter_common.py`
    - `prepare_grad_etc` 改为恢复 adapter 参数 `requires_grad=True`，并显式将注入层设为 `train()`。
    - `on_epoch_start` 同步恢复参数可训练状态，避免 `unet.requires_grad_(False)` 后 adapter 长期冻结。
  - `anima_train_network.py`
    - 移除训练路径中 `preprocess_text_embeds(...)` 的 `torch.no_grad()` 包裹（Qwen 仍保持 `no_grad=True`）。
    - 维持 T5 强依赖校验（`t5_tokenizer_dir` 必填、batch 中 `t5_ids` 缺失直接报错）。
  - `library/strategy_anima.py`
    - 增加 `t5_input_ids` 非空校验，禁止无 T5 回退路径。
  - `library/anima_backend/modelling/anima_modeling.py`
    - 增加 `enable_gradient_checkpointing` no-op 兼容接口，避免外部误调用崩溃。
  - `tools/convert_anima_root_to_kohya.py`
    - 增加 `model.t5_tokenizer_dir / model.t5_tokenizer_path` 强校验；缺失时报清晰错误。
  - 文档与模板更新：
    - `docs/anima_train_network.md`、`README.md`、`README-ja.md` 明确 LLMAdapter 训练语义默认启用且 T5 必需。
    - `configs/smoke/anima_10steps_train_args.toml` 增加 T5 必填说明注释。
- 测试更新与验证：
  - 更新 `tests/test_anima_network_modules.py`：新增 `unet.requires_grad_(False)` 后 `prepare_grad_etc` 恢复断言。
  - 更新 `tests/test_anima_process_batch.py`：新增
    - 缺失 `t5_ids` 报错断言；
    - `preprocess_text_embeds` 梯度可回传断言。
  - 更新 `tests/test_anima_config_converter.py`：新增缺失 T5 配置转换失败断言。
  - 在 venv 安装 `pytest` 后执行：
    - `pytest -q tests/test_anima_network_modules.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_scheduler_num_cycles_float.py tests/test_anima_config_converter.py`
    - 结果：`16 passed`。
  - 训练输出：
  - 结果：训练 10 steps 成功完成，退出码 `0`。
  - 权重体检：`lokr_w2_b` 不再全零（`0/340` 为零，`340/340` 非零），与修复目标一致。
- 新增“训练启动时自动下载 T5 文件”能力：
  - `library/anima_runtime/model_loading.py`
    - 新增 `T5_DEFAULT_REPO_ID=google/t5-v1_1-base`。
    - 新增缺失文件检测与自动下载流程：当 `t5_tokenizer_dir` 缺 `config.json` / `spiece.model` / `tokenizer.json` 时，默认自动下载并落盘。
    - `load_t5_tokenizer(...)` 扩展参数：
      - `auto_download`（默认 `True`）
      - `repo_id`（默认 `google/t5-v1_1-base`）
    - 下载后强制本地加载（`local_files_only=True`）。
  - `library/anima_models.py`
    - `load_anima_t5_tokenizer` 支持透传自动下载参数。
  - `anima_train_network.py`
    - 新增 CLI 参数：
      - `--auto_download_t5_tokenizer/--no-auto_download_t5_tokenizer`
      - `--t5_tokenizer_repo_id`
    - `get_tokenize_strategy` 调用 T5 加载时传入上述参数。
- 文档更新：
  - `docs/anima_train_network.md`：增加自动下载参数与行为说明。
  - `README.md` / `README-ja.md`：增加“默认自动下载 T5 文件”说明。
- 新增测试：
  - `tests/test_anima_t5_auto_download.py`
    - 覆盖“缺文件自动下载”路径。
    - 覆盖“关闭自动下载时缺文件直接报错”路径。
- 测试执行：
  - `pytest -q tests/test_anima_t5_auto_download.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_network_modules.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`18 passed`。
- 真实下载验证：
  - 通过 `load_t5_tokenizer('output/t5_autodl_smoke_<uuid>', auto_download=True)` 在启动阶段成功自动下载并生成所需文件：
    - `config.json`
    - `spiece.model`
    - `tokenizer.json`
- 按“Comfy-only 导出 + train_norm 默认开启”实施细化修复：
  - `anima_train_network.py`
    - 新增 `--train_norm/--no-train_norm`（默认 `True`）。
    - 新增 `apply_anima_network_defaults(args)`，在启动阶段将 `train_norm=<true|false>` 强制注入 `network_args`，确保网络模块可读取。
  - `networks/_anima_adapter_common.py`
    - 新增统一布尔解析 `_parse_bool`，修复字符串布尔值误判风险。
    - `apply_to` 增加 Norm 参数收集（`LayerNorm` / `RMSNorm` / 自定义 `RMSNorm` 类名识别），并把 Norm 参数加入训练参数集合。
    - 记录 Norm 初始参数快照，导出时以差分写入 `w_norm/b_norm`。
    - 导出改为 Comfy-only 键：统一写入 `diffusion_model.*`。
    - LoRA/LoKr 导出新增 `.alpha` 键，避免缩放语义丢失。
    - 加载逻辑支持 Comfy 键回读（含 `diffusion_model.*` 与旧格式兼容），并支持 Norm 差分回填。
- 新增/更新测试：
  - 更新 `tests/test_anima_network_modules.py`
    - 增加 `train_norm=true/false` 行为断言；默认开启时 Norm 参数进入优化器参数集。
    - Dummy 模型增加 `llm_adapter` 与 norm 结构覆盖。
  - 更新 `tests/test_anima_train_network.py`
    - 增加 `--train_norm` 默认值、`--no-train_norm` 解析、`network_args` 注入断言。
  - 新增 `tests/test_anima_comfy_export_keys.py`
    - 断言导出键全部以 `diffusion_model.` 开头。
    - 断言 LoRA/LoKr 后缀、`.alpha`、`w_norm/b_norm`、`llm_adapter` 键存在。
- 文档同步：
  - `docs/anima_train_network.md`：补充 `train_norm` 默认开启、Comfy-only 导出、`--resume` 续训建议。
  - `README.md` / `README-ja.md`：补充上述行为摘要。
- 回归验证：
  - `pytest -q tests/test_anima_independence.py tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py tests/test_anima_config_converter.py`
  - 结果：`24 passed`。
  - 结果：10 steps 成功完成，输出：
  - 权重体检：
    - 全部键满足 `diffusion_model.*`。
    - 包含 `llm_adapter`、`w_norm`、`.alpha`、`lokr_w2_b`。
    - `lokr_w2_b` 非零比例 `1.0`（`768000/768000`）。
    - metadata 中 `ss_network_args` 含 `{"train_norm": "true", ...}`。
- 按“LoKr Full-Matrix Sentinel + Cosmos T5 回退”计划完成实现：
  - `networks/_anima_adapter_common.py`
    - 引入 `network_dim >= 100000` 的 Kohya/LyCORIS sentinel 语义：自动强制 `lokr_full_matrix=true`（不改写 dim）。
    - 增加触发日志，便于训练日志可观测性。
  - `library/anima_runtime/model_loading.py`
    - 新增 T5 源解析：支持 HF repo id、HF URL、ModelScope URL。
    - 新增 `repo_subfolder`、ModelScope fallback 配置参数。
    - 自动下载改为 HF 优先；HF 失败（含 gated/网络异常）后自动回退 ModelScope。
  - `anima_train_network.py`
    - 新增并透传参数：
      - `--t5_tokenizer_subfolder`
      - `--t5_tokenizer_modelscope_fallback/--no-t5_tokenizer_modelscope_fallback`
      - `--t5_tokenizer_modelscope_repo_id`
      - `--t5_tokenizer_modelscope_revision`
      - `--t5_tokenizer_modelscope_subfolder`
    - `network_dim = 100000`（full-matrix sentinel）
    - T5 下载源改为 `https://huggingface.co/nvidia/Cosmos-Predict2-2B-Text2Image/tree/main/tokenizer`
    - 开启并配置 ModelScope 自动回退。
- 新增/更新测试：
  - `tests/test_anima_network_modules.py`
    - 新增 `network_dim=100000` 自动 full-matrix 断言。
  - `tests/test_anima_t5_auto_download.py`
    - 新增 HF 成功不回退、HF 失败回退 ModelScope、HF/HF URL/ModelScope URL 解析断言。
  - `tests/test_anima_train_network.py`
    - 新增 ModelScope fallback CLI 默认值与关闭开关解析断言。
- 测试验证：
  - `pytest -q tests/test_anima_network_modules.py tests/test_anima_train_network.py tests/test_anima_t5_auto_download.py tests/test_anima_process_batch.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`30 passed`。
  - `pytest -q tests/test_anima_independence.py tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`34 passed`。
- 实测验证：
  - T5 回退下载验证：使用 HF Cosmos URL 作为源，触发 HF gated 后自动回退 ModelScope 成功，下载并校验文件：
    - `config.json`
    - `spiece.model`
    - `tokenizer.json`
    - `tokenizer_config.json`
    - `special_tokens_map.json`
    - 输出：
    - 日志确认 sentinel 触发：`network_dim=100000 >= 100000, forcing lokr_full_matrix=true`
    - 权重体检：存在 `.lokr_w2`、不存在 `.lokr_w2_b`（符合 full-matrix 预期），键前缀全部为 `diffusion_model.*`。
- 按“sd-scripts-anima × Anima_Trainer 稳定性优先”计划补齐三项能力：
  - 续训一致性快照：
    - `train_network.py` 新增通用 hook：`build_resume_snapshot` / `validate_resume_snapshot`，并在 save/load state hook 中读写 `resume_snapshot.json`。
    - `anima_train_network.py` 实现 Anima 侧关键字段快照与严格差异校验（不一致时启动阶段直接报错）。
  - 训练监控增强：
    - `anima_train_network.py` 新增 `--anima_monitor_*` 参数（显存监控、告警策略、阈值配置）。
    - step logs 增加 `gpu/mem_*` 与 `alert/*` 指标；`alert_policy=raise` 时对 `nonfinite_loss` / `memory_near_limit` 触发中断。
  - T5 严格校验：
    - `library/anima_runtime/model_loading.py` 新增 `strict_validation` 路径；
    - `--t5_tokenizer_validate_strict` 接入 `anima_train_network.py`；
    - 严格模式校验 special token、id 范围与本地 smoke encode。
- 测试补充：
  - 新增 `tests/test_anima_resume_snapshot.py`。
  - 新增 `tests/test_anima_monitoring.py`。
  - 更新 `tests/test_anima_train_network.py`（新 CLI 参数默认值与解析）。
  - 更新 `tests/test_anima_t5_auto_download.py`（strict 模式成功/失败路径）。
  - 更新 `tests/anima_entry_test_utils.py`（stub `NetworkTrainer` 增加 log/snapshot 接口）。
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_t5_auto_download.py tests/test_anima_resume_snapshot.py tests/test_anima_monitoring.py tests/test_anima_network_modules.py tests/test_anima_process_batch.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py`
  - 结果：`43 passed`。

## 2026-02-11

- 读取并遵循 `AGENTS.md`、`.ai/claude.prompt.md`、`.ai/context/01-overview.md`。
- 对比分析 ComfyUI 两个 Anima LoKr 权重：
  - `E:\AI\ComfyUI\models\loras\anima\zxiong\e50\newzx-anima-lokr.safetensors`
  - `E:\AI\ComfyUI\models\loras\anima\3in1\DragonOCs-anima-lokr.safetensors`
- 关键结论：
  - 两者均为 Comfy 前缀键（`diffusion_model.*`），目标模块覆盖总体一致。
  - `newzx` 为 `networks.lokr_anima` 导出，启用 `train_norm=true`，且为 full-matrix 形态（存在 `.lokr_w2`，无 `.lokr_w2_b`）。
  - `DragonOCs` 为 `lycoris.kohya` 导出（`algo=lokr, full_matrix=true`）。
  - `newzx` metadata 显示实际训练总步数 `ss_steps=300`（`ss_epoch=50`，`batch=6`，`grad_accum=6`）。
  - 权重强度对比：`newzx` 的 `lokr_w2` 平均绝对值约 `0.00063`，`DragonOCs` 约 `0.00161`，前者约为后者 `39%`，整体更弱；`newzx` 另含 norm 差分键（`w_norm/b_norm`）。
- 结论用于答复用户“为什么一个能吐原图、一个不能”：更可能是训练步数/有效更新不足与权重强度偏弱叠加所致，而非基础键格式不兼容。
- 复核 `anima_train_network.py` 当前网络加载约束：`SUPPORTED_NETWORK_MODULES=("networks.lora_anima", "networks.lokr_anima")`，默认回落为 `networks.lora_anima`，不接受 `lycoris.kohya` 作为训练入口模块。
- 结论：当前 `sd-scripts-anima` 训练脚本使用本仓 Anima 适配实现（内置 LoRA/LoKr 注入），并非直接依赖 LyCORIS 训练实现；但导出权重仍兼容常见 LoKr 语义（含 full-matrix sentinel 行为）。
- 按“参考 LyCORIS 实现但保持键名与训练层不变”完成网络实现细化：
  - 修改 `networks/_anima_adapter_common.py`：
    - 为 `_LoRALayer` / `_LoKrLayer` 增加 `set_alpha(...)`，支持从权重 `.alpha` 回读并即时更新缩放。
    - `_LoKrLayer` 的 rank dropout 改为按 rank 维度掩码并进行 `1/(1-p)` 期望缩放补偿，语义更贴近 LyCORIS。
    - 保持导出键名不变：仍为 `diffusion_model.*`，并继续导出 `.alpha`。
    - 保持训练层筛选不变：仍由既有 `target_modules` 匹配逻辑决定。
    - `_load_adapter_state_dict` 新增 `.alpha` 读取并应用到对应 layer adapter（仅行为对齐，不改变键结构）。
- 新增测试（`tests/test_anima_network_modules.py`）：
  - `test_lora_alpha_is_restored_from_weights`
  - `test_lokr_alpha_is_restored_from_weights`
  - 验证从 safetensors 加载后 `.alpha` 会正确恢复并影响 scaling。
- 验证：
  - `python -m pytest -q tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py` -> `8 passed`
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py` -> `28 passed`
- 按需求实现“默认 TensorBoard + 实验名日志命名 + xformers 完整支持”：
  - `anima_train_network.py`
    - 新增 `apply_anima_runtime_defaults(args)`：
      - 默认启用 `log_with=tensorboard`；
      - 默认日志根目录为 `<output_dir>/logs`（无 `output_dir` 时为 `logs`）；
      - 默认 `log_prefix=<output_name>_`（用于组合“实验名 + 时间戳”目录）；
      - 兼容历史拼写 `xfomers` 并映射到 `xformers`。
    - 在 `__main__` 流程中接入 `apply_anima_runtime_defaults(args)`。
    - 在 `assert_extra_args` 中补齐 xformers backend 选择逻辑：
      - `--xformers` 强制 `anima_attention_backend=xformers`；
      - 若 xformers 不可用，自动回退 `torch` 并输出 warning。
    - 增加 `--xfomers` 兼容参数（若基类未定义时注册，避免冲突）。
  - `library/train_util.py`
    - `prepare_accelerator` 改为仓库级默认启用 TensorBoard（未指定 `log_with` 时）。
    - 默认日志根目录：未传 `logging_dir` 时自动使用 `<output_dir>/logs`（无 `output_dir` 时 `logs`）。
    - 日志目录命名改为“实验名 + 详细日期”：`<log_prefix><YYYYMMDD_HHMMSS_ffffff>`。
- 测试更新：
  - `tests/test_anima_train_network.py`
    - 新增运行时日志默认值断言；
    - 新增 `xfomers` 兼容映射断言；
    - 新增 xformers 可用/不可用时 backend 选择与回退断言（monkeypatch `_is_xformers_available`）。
  - `tests/anima_entry_test_utils.py`
    - 补充 stub parser 字段：`logging_dir/log_with/log_prefix/mem_eff_attn/sdpa/xfomers`。
- 文档同步：
  - `docs/anima_train_network.md`：新增默认 TensorBoard、日志命名规则、xformers 行为与 `xfomers` 兼容说明。
  - `README.md` / `README-ja.md`：Anima 条目补充默认日志与 xformers 行为摘要。
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_process_batch.py tests/test_anima_network_modules.py tests/test_anima_comfy_export_keys.py` -> `31 passed`。
  - `python -m compileall anima_train_network.py library/train_util.py networks/_anima_adapter_common.py` 通过。
- 补全 `configs/kieed.toml` 为可调参数模板：
  - 保留现有 Kieed 训练核心参数并修正输出命名（`output_dir/output_name` 对应 kieed）。
  - 按模块新增/补齐常用可调项与注释：
    - T5 自动下载与 strict 校验
    - LoRA/LoKr（含 `network_args` 示例）
    - 保存/续训策略（state/steps/epochs）
    - 学习率调度扩展参数
    - 运行时与注意力后端（xformers/legacy `xfomers` 说明）
    - 日志与 tracker（TensorBoard 默认行为说明）
    - Anima 监控告警参数
    - 数据增强与 bucket 扩展参数
- 执行 TOML 语法校验：`toml.load('configs/kieed.toml')` 通过（`58` keys）。
- 按用户要求重排 `configs/kieed.toml`：
  - 将常用参数前置（模型路径、T5、数据集、训练核心、网络与输出、性能设置）。
  - 全量注释改为中英双语（中文 + English）。
  - 保持现有训练值不变，仅调整组织结构与注释可读性。
- 语法校验：`toml.load('configs/kieed.toml')` 通过（`58` keys）。
- 修正 `configs/kieed.toml` 关键配置错误：
  - `anima_attention_backend` 从 `"xfomers"` 更正为 `"xformers"`（前者不在允许值内，会触发 argparse choices 校验失败）。
  - 将底部兼容别名 `xfomers = true` 改为注释，避免与 `xformers = true` 重复定义造成混淆。
- 执行 TOML 校验：`toml.load('configs/kieed.toml')` 通过（`60` keys）。
- 排查“TensorBoard 在哪里”：
  - 发现事件文件已生成：
    - `E:\sd-scripts-anima\output\kieed_e20_bs6\logs\kieed-anima-lokr_20260211_152511_753629\network_train\events.out.tfevents.1770794863.DESKTOP-3090.64924.0`
  - 发现 TensorBoard 启动失败原因为：`ModuleNotFoundError: No module named 'pkg_resources'`（当前环境 `setuptools==82.0.0` 不再提供该模块）。
  - 修复：将 venv 中 `setuptools` 降级到 `<81`（安装为 `80.10.2`），随后验证：
    - `python -m tensorboard.main --version` -> `2.20.0` 成功。
- 按“最快启动训练”目标重写 README：`README.md` 改为中英双语 Quick Start，聚焦最小可运行路径（安装 -> 数据 -> 配置 -> 启动 -> TensorBoard）。
- 新增依赖安装向导：`docs/anima_dependency_guide.md`（中英双语，含 Windows/Linux、xformers 可选安装与常见报错处理）。
- 重写 `docs/anima_train_network.md` 为精简版中英双语说明，保留最小必填参数与高频参数，移除不常用参数说明。
- 新增精简示例（参考 `configs/kieed.toml` 并去除低频项）：
  - `configs/examples/anima_quickstart_train_args.toml`
  - `configs/examples/anima_quickstart_dataset.toml`
- 语法校验：使用 `tomllib` 解析上述两个示例 TOML，均通过。
- 对本地剩余改动执行回归验证（xformers/TensorBoard 默认行为与 LoRA/LoKr alpha 加载相关变更）：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_network_modules.py tests/test_anima_process_batch.py tests/test_anima_t5_auto_download.py tests/test_anima_comfy_export_keys.py tests/test_anima_config_converter.py tests/test_scheduler_num_cycles_float.py tests/test_anima_resume_snapshot.py tests/test_anima_monitoring.py`
  - 结果：`51 passed`。
- 执行语法校验：`python -m compileall anima_train_network.py library/train_util.py networks/_anima_adapter_common.py tests/anima_entry_test_utils.py tests/test_anima_network_modules.py tests/test_anima_train_network.py` 通过。
- 按用户要求提交其余本地改动，`configs/kieed.toml` 继续保持未跟踪且不纳入提交。
- 响应用户问题“为什么 Anima 训练需要 T5 tokenizer + 给出训练路径”并完成代码路径核对：
  - `anima_train_network.py`：`t5_tokenizer_dir` 为必填，缺失直接报错；训练 batch 缺 `t5_ids` 直接报错；前向使用 `preprocess_text_embeds(qwen_embeds, t5_ids)`。
  - `library/strategy_anima.py`：tokenize 阶段强制需要 `t5_tokenizer`，并返回 `[qwen_ids, qwen_attention_mask, t5_ids]`；编码策略缺 `t5_input_ids` 直接报错。
  - `library/anima_runtime/model_loading.py`：`load_t5_tokenizer` 会校验 `config.json/spiece.model/tokenizer.json`，缺文件默认自动下载（HF 优先，失败回退 ModelScope）。
  - 文档路径确认：`docs/anima_train_network.md` 与 `README.md` 的最小启动命令均为 `accelerate launch anima_train_network.py --config_file ... --dataset_config ...`。
- 按用户要求调整 README 的 TOML 示例形式：
  - 将快速开始示例改为“单文件 root-style”流程，新增 `configs/examples/anima_quickstart_single.toml`。
  - 在 README 中明确展示 `[model]`、`[dataset]`、`[training]`、`[lora]`、`[optimizer]`、`[output]` 分区。
  - 新增“先转换后训练”步骤：通过 `tools/convert_anima_root_to_kohya.py` 生成 `train_args.toml` 与 `dataset.toml` 后再启动训练。
- 校验：使用 `tomllib` 成功解析 `configs/examples/anima_quickstart_single.toml`（sections: dataset/lora/model/optimizer/output/training）。
- 排查“xformers 似乎无法启用”问题并修复：
  - `anima_train_network.py` 的 `apply_anima_runtime_defaults` 中，兼容别名 `xfomers=false` 会误覆盖 `xformers=true`。
  - 调整为仅在 `xfomers` 为显式 truthy（`True` 或字符串 true/yes/on/1）时才映射到 `xformers=true`，不再用 false/default 值反向关闭 xformers。
- 新增测试：`tests/test_anima_train_network.py`
  - `test_apply_anima_runtime_defaults_legacy_xfomers_false_does_not_disable_xformers`
  - 覆盖“`xformers=true` 不应被 `xfomers=false` 误关闭”场景。
- 验证：`python -m pytest -q tests/test_anima_train_network.py` -> `21 passed`。
- 补充可观测性：在 `AnimaNetworkTrainer.assert_extra_args` 完成 backend 选择后，新增 info 日志输出最终结果：
  - `Anima attention backend resolved to '<backend>' (xformers=<bool>)`
  - 用于直接确认训练实际是否启用 xformers。
- 回归：再次执行 `python -m pytest -q tests/test_anima_train_network.py`，结果 `21 passed`。
- 根据用户反馈“README 没写单文件示例”，将 `configs/examples/anima_quickstart_single.toml` 前置到 `README.md` 顶部，新增 `Quickstart Files / 快速入口文件` 区块，集中列出单文件模板、转换器与训练入口，提升可见性。
- 按用户要求更新 README 硬件建议：
  - 将中文与英文的推荐显存从 `>= 12GB` 调整为 `>= 16GB`。
- 按用户反馈将 README 的数据集示例改为 Kohya-style：
  - 中文/英文第 3 节均改为 `train/10_kieed/` 结构示例（图片与同名 `.txt`）。
  - 增加说明：`dataset.data_dir` 指向 `.../train/10_kieed`，重复次数由 `dataset.repeats` 控制。
- 同步更新 `configs/examples/anima_quickstart_single.toml`：
  - `dataset.data_dir` 示例路径改为 `/path/to/train/10_kieed`。
- 按用户要求移除 README 与示例配置中的指名道姓样例命名：
  - 将 `10_kieed` 全部替换为中性占位 `10_subject`。
  - 更新位置：`README.md`（中英数据集示例与 `dataset.data_dir` 说明）、`configs/examples/anima_quickstart_single.toml`（`dataset.data_dir` 示例路径）。
- 全局校验：目标文件中不再包含 `kieed`/`10_kieed`。
- 按用户要求将 README 训练流程改为“单文件 TOML 直接拉起”，不再要求手动执行转换脚本：
  - `accelerate launch anima_train_network.py --config_file configs/examples/anima_quickstart_single.toml`
  - 文档中注明入口会自动检测 root-style 单文件并自动转换为 Kohya 训练参数与数据集配置。
- 在 `anima_train_network.py` 增加单文件自动转换能力：
  - 新增 `maybe_auto_convert_single_file_config(args)`，检测 `config_file` 是否 root-style（含 `[model]` + `[training]`）。
  - 自动调用 `tools/convert_anima_root_to_kohya.py` 的转换逻辑并生成临时 `train_args.toml` + `dataset.toml`，然后回填 `args.config_file/args.dataset_config`。
- 修复 `library/train_util.py::read_config_from_file` 在部分 parser 默认值下 `args.config_file=None` 导致 `splitext` 报错的问题，改为稳健分支处理。
- README 新增“训练 + TensorBoard 一键启动”PowerShell 片段：
  - 自动探测空闲端口（从 6006 递增）。
  - 启动 TensorBoard 并在控制台打印 `http://127.0.0.1:<port>`。
- 新增测试：`tests/test_anima_train_network.py`
  - `test_maybe_auto_convert_single_file_config_for_root_style`
  - `test_maybe_auto_convert_single_file_config_skips_non_root_style`
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_config_converter.py tests/test_anima_t5_auto_download.py` -> `34 passed`
  - `python -m compileall anima_train_network.py library/train_util.py tests/test_anima_train_network.py` 通过。
- 按“单文件配置统一”方案完成实现（Anima 入口）：
  - `anima_train_network.py`：`maybe_auto_convert_single_file_config` 从“临时文件转换”改为“内存内转换”，不再落地 `train_args.toml` / `dataset.toml`。
  - 自动识别 root-style 单文件（`[model]` + `[training]`）并映射到 Kohya 参数。
  - 冲突策略落地：若同时提供单文件 `[dataset]` 与 `--dataset_config`，优先使用 CLI 的 `--dataset_config`，并打印 warning。
  - `__main__` 流程改为：先尝试单文件内存适配；仅在未命中时走 `train_util.read_config_from_file`，保持两文件模式兼容。
- `library/config_util.py`：`load_user_config` 扩展支持 `dict` 输入（兼容旧有 `str/Path` 文件输入）。
- `train_network.py`：当 `args.dataset_config` 为 `dict` 时输出可读日志：`Loading dataset config from inline single-file [dataset] section.`。
- 文档更新：
  - `README.md`：明确单文件自动内存转换、不落地中间文件；补充 `--dataset_config` 覆盖优先级说明。
  - `docs/anima_train_network.md`：改为主推单文件 root-style，并说明两文件兼容与覆盖规则。
- 测试更新：
  - `tests/anima_entry_test_utils.py`：stub parser 增加 `--config_file/--dataset_config`。
  - `tests/test_anima_train_network.py`：更新单文件转换断言（`dataset_config` 为 `dict`，不再依赖临时文件）；新增 CLI 覆盖 inline dataset 的 warning 断言。
  - `tests/test_anima_config_converter.py`：新增 `load_user_config` 支持内联 dict 的测试。
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py tests/test_anima_config_converter.py tests/test_anima_t5_auto_download.py tests/test_anima_process_batch.py tests/test_anima_network_modules.py` -> `45 passed`
  - `python -m compileall anima_train_network.py library/config_util.py train_network.py tests/test_anima_train_network.py tests/anima_entry_test_utils.py tests/test_anima_config_converter.py` 通过。
- 追加稳健性修正：`maybe_auto_convert_single_file_config` 在 `--output_config` 场景下直接跳过自动转换，保留原有 `read_config_from_file` 输出配置行为。
- 新增测试：`test_maybe_auto_convert_single_file_config_skips_when_output_config_enabled`。
- 回归复测：`pytest` 相关 5 组共 `46 passed`。
- 按用户要求批量处理外部数据集目录 `E:\lora-scripts-v1.10.0\train\konya_karasue\10_konyakarasue` 的 caption（75 个 `.txt`）：
  - 统一将角色标签置于开头为 `@konya karasue`（并去重原有 `konya_karasue/konya karasue` 标签）。
  - 将全部标签中的下划线 `_` 替换为空格。
- 校验结果：
  - `files_with_underscore=0`
  - `files_without_prefix=0`
- 按用户要求更新 `README.md` 的 TensorBoard 说明：
  - 删除“训练 + TensorBoard 一键同启”脚本示例。
  - 改为明确“TensorBoard 需要在另一个终端单独启动”。
  - 提供固定端口命令与访问地址：`http://127.0.0.1:6006`。
- 按用户要求实现“训练时自动拉起 TensorBoard Web 服务”：
  - `anima_train_network.py` 新增 `maybe_start_tensorboard(args)`，在 `trainer.train(args)` 前自动启动 TensorBoard。
  - 仅主进程执行自动拉起（避免分布式多进程重复启动）。
  - 当 `log_with=tensorboard/all` 且 `auto_start_tensorboard=true` 时生效；控制台打印 URL。
  - 默认端口 `6006` 占用时自动顺延到可用端口并告警。
  - 新增参数：`--auto_start_tensorboard/--no-auto_start_tensorboard`、`--tensorboard_host`、`--tensorboard_port`、`--tensorboard_logdir`。
- 测试更新：
  - `tests/test_anima_train_network.py` 新增自动拉起相关断言（默认值、启动条件、非主进程跳过、端口回退）。
- 文档更新：
  - `README.md` 与 `docs/anima_train_network.md` 同步为“默认自动拉起 TensorBoard”，并补充可选开关参数。
- 验证：
  - `python -m pytest -q tests/test_anima_train_network.py` -> `30 passed`
  - `python -m pytest -q tests/test_anima_process_batch.py tests/test_anima_network_modules.py tests/test_anima_t5_auto_download.py` -> `18 passed`
- 调整 Anima 入口日志目录默认值：
  - `anima_train_network.py::apply_anima_runtime_defaults` 在未显式设置 `logging_dir` 时，默认改为固定 `./logs`（不再跟随 `output_dir`）。
  - 同步更新 `README.md` 与 `docs/anima_train_network.md` 的默认日志目录说明为 `./logs/<output_name>_...`。
  - 更新测试断言并回归：`python -m pytest -q tests/test_anima_train_network.py` -> `30 passed`。
