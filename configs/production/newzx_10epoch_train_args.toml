anima_transformer = "E:/sd-scripts-anima/anima-models/diffusion_models/anima-preview.safetensors"
pretrained_model_name_or_path = "E:/sd-scripts-anima/anima-models/diffusion_models/anima-preview.safetensors"
vae = "E:/sd-scripts-anima/anima-models/vae/qwen_image_vae.safetensors"
qwen = "E:/sd-scripts-anima/anima-models/text_encoders"
t5_tokenizer_dir = "E:/sd-scripts-anima/anima-models/t5/t5_old"

network_module = "networks.lokr_anima"
network_dim = 16
network_alpha = 16

dataset_config = "configs/production/newzx_dataset.toml"

output_dir = "E:/sd-scripts-anima/output/newzx_e10_bs8"
output_name = "newzx_lokr_e10_bs8_lr1e4"
save_model_as = "safetensors"
save_every_n_epochs = 1

max_train_epochs = 10
learning_rate = 0.0001
lr_scheduler = "constant"
lr_warmup_steps = 0

train_batch_size = 8
gradient_accumulation_steps = 4
mixed_precision = "bf16"
gradient_checkpointing = true
cache_latents = true
xformers = true
max_data_loader_n_workers = 2
persistent_data_loader_workers = true

optimizer_type = "AdamW8bit"
optimizer_args = ["weight_decay=0.01", "eps=1e-08", "betas=(0.9,0.95)"]

seed = 42
anima_seq_len = 128
anima_noise_offset = 0.0
